Identifying emotions from voice. Based on [this blog post](https://towardsdatascience.com/detecting-emotions-from-voice-clips-f1f7cc5d4827)

Relevant resources:

* [LibROSA](https://librosa.org/librosa/)
* [Understanding the Mel Spectrogram](https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53)
* [The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)](https://zenodo.org/record/1188976#.Xuxu92ozadY)
* [Toronto emotional speech set (TESS)](https://tspace.library.utoronto.ca/handle/1807/24487)
* [The LJ Speech Dataset](https://keithito.com/LJ-Speech-Dataset/)
* [How To Apply Machine Learning And Deep Learning Methods to Audio Analysis](https://hackernoon.com/how-to-apply-machine-learning-and-deep-learning-methods-to-audio-analyis-wt6p32qz)
* [Musical Genre Classification with Convolutional Neural Networks](https://towardsdatascience.com/musical-genre-classification-with-convolutional-neural-networks-ff04f9601a74)
* [Deep Learning Approaches for Understanding Simple SpeechCommands](https://arxiv.org/pdf/1810.02364.pdf)
* [DeepMind's Tacotron-2 Tensorflow implementation](https://github.com/Rayhane-mamah/Tacotron-2)
